{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Nobelizer\n",
    "\n",
    "## by Catalin Vasii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I thoght a little tool to get a Nobel Prize in lit would be useful. This notebook is a recurrent neural network in the style of [Jeremy Howard's fast.ai](http://www.fast.ai/) that has been trained onall Bob Dylan song lyrics to predict the next character for each given sequence of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout\n",
    "from keras.layers import TimeDistributed, Activation, LSTM\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from numpy.random import choice\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 563887\n"
     ]
    }
   ],
   "source": [
    "path = 'dylansongs.txt'\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flowers on the hillside blooming crazy\r\n",
      "Crickets talking back and forth in rhyme\r\n",
      "Blue river running slow and lazy\r\n",
      "I could stay with you forever and never realize the time\r\n",
      "\r\n",
      "Situations have ended sad\r\n",
      "Relationships have all been bad\r\n",
      "Mine have been like Verlaine's and Rimbaud's\r\n",
      "But there's no way I can compare\r\n",
      "All them scenes to this affair,\r\n",
      "You're gonna make me lonesome when you go\r\n",
      "\r\n",
      "You're gonna make me wonder what I'm doing\r\n",
      "Staying far behind without you\r\n",
      "You're gonna make me wonder what I'm saying\r\n",
      "You're gonna make me give myself a good talking to\r\n",
      "\r\n",
      "I'll look for you in old Honolulu\r\n",
      "San Francisco or Ashtabula\r\n",
      "You're gonna have to leave me now I know\r\n",
      "But I'll see you in the sky above\r\n",
      "In the tall grass in the ones I love\r\n",
      "You're gonna make me lonesome when you go/nNone/nNone/n"
     ]
    }
   ],
   "source": [
    "!tail {path} -n23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 58\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-./0123456789:;?[]abcdefghijklmnopqrstuvwxy'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are constructing two dictionaries, mapping characters to numbers (index in the text) and conversely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46, 31, 40, 2, 46, 34, 41, 47, 45, 27]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ten thousand men on a hill,\\nsome of 'm goin' down, some of 'm gonna ge\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 563852\n"
     ]
    }
   ],
   "source": [
    "maxlen = 36\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(idx) - maxlen+1):\n",
    "    sentences.append(idx[i: i + maxlen])\n",
    "    next_chars.append(idx[i+1: i+maxlen+1])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first two sentences are:  [[46, 31, 40, 2, 46, 34, 41, 47, 45, 27, 40, 30, 2, 39, 31, 40, 2, 41, 40, 2, 27, 2, 34, 35, 38, 38, 8, 1, 45, 41, 39, 31, 2, 41, 32, 2], [31, 40, 2, 46, 34, 41, 47, 45, 27, 40, 30, 2, 39, 31, 40, 2, 41, 40, 2, 27, 2, 34, 35, 38, 38, 8, 1, 45, 41, 39, 31, 2, 41, 32, 2, 5]]\n",
      "first two next chars are:  [[31, 40, 2, 46, 34, 41, 47, 45, 27, 40, 30, 2, 39, 31, 40, 2, 41, 40, 2, 27, 2, 34, 35, 38, 38, 8, 1, 45, 41, 39, 31, 2, 41, 32, 2, 5], [40, 2, 46, 34, 41, 47, 45, 27, 40, 30, 2, 39, 31, 40, 2, 41, 40, 2, 27, 2, 34, 35, 38, 38, 8, 1, 45, 41, 39, 31, 2, 41, 32, 2, 5, 39]]\n"
     ]
    }
   ],
   "source": [
    "print('first two sentences are: ' ,sentences[:2])\n",
    "print('first two next chars are: ' ,next_chars[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((563850, 36), (563850, 36))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.shape, next_chars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is Jeremy Howard's approach to use embeddings instead of one hot encodings. We set the number of latent factor to 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short Time Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras has three types of recurrent layers: LSTM, GRU and SimpleRNN. The first two are more complex, I will only put a scheme of a LSTM, i.e. Long Short Time Memory: \n",
    "\n",
    "![](Long_Short_Term_Memory.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=maxlen),\n",
    "        BatchNormalization(),    \n",
    "        LSTM(512, input_dim=n_fac,return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        LSTM(512, return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size)),\n",
    "        Activation('softmax')\n",
    "    ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphically, the network looks like below, but keep in mind that each of the two recurrent layers look like in the above picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"629pt\" viewBox=\"0.00 0.00 314.00 629.00\" width=\"314pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-625 310,-625 310,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140217787892848 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140217787892848</title>\n",
       "<polygon fill=\"none\" points=\"56.5,-584.5 56.5,-620.5 249.5,-620.5 249.5,-584.5 56.5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-598.8\">embedding_input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140217787789264 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140217787789264</title>\n",
       "<polygon fill=\"none\" points=\"72.5,-511.5 72.5,-547.5 233.5,-547.5 233.5,-511.5 72.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-525.8\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 140217787892848&#45;&gt;140217787789264 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140217787892848-&gt;140217787789264</title>\n",
       "<path d=\"M153,-584.313C153,-576.289 153,-566.547 153,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-557.529 153,-547.529 149.5,-557.529 156.5,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140217787891784 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140217787891784</title>\n",
       "<polygon fill=\"none\" points=\"26.5,-438.5 26.5,-474.5 279.5,-474.5 279.5,-438.5 26.5,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-452.8\">batchnormalization_1: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140217787789264&#45;&gt;140217787891784 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140217787789264-&gt;140217787891784</title>\n",
       "<path d=\"M153,-511.313C153,-503.289 153,-493.547 153,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-484.529 153,-474.529 149.5,-484.529 156.5,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140217787891840 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140217787891840</title>\n",
       "<polygon fill=\"none\" points=\"104,-365.5 104,-401.5 202,-401.5 202,-365.5 104,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-379.8\">lstm_1: LSTM</text>\n",
       "</g>\n",
       "<!-- 140217787891784&#45;&gt;140217787891840 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140217787891784-&gt;140217787891840</title>\n",
       "<path d=\"M153,-438.313C153,-430.289 153,-420.547 153,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-411.529 153,-401.529 149.5,-411.529 156.5,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140217787892064 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140217787892064</title>\n",
       "<polygon fill=\"none\" points=\"90.5,-292.5 90.5,-328.5 215.5,-328.5 215.5,-292.5 90.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-306.8\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 140217787891840&#45;&gt;140217787892064 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140217787891840-&gt;140217787892064</title>\n",
       "<path d=\"M153,-365.313C153,-357.289 153,-347.547 153,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-338.529 153,-328.529 149.5,-338.529 156.5,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140217787892176 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140217787892176</title>\n",
       "<polygon fill=\"none\" points=\"104,-219.5 104,-255.5 202,-255.5 202,-219.5 104,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-233.8\">lstm_2: LSTM</text>\n",
       "</g>\n",
       "<!-- 140217787892064&#45;&gt;140217787892176 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140217787892064-&gt;140217787892176</title>\n",
       "<path d=\"M153,-292.313C153,-284.289 153,-274.547 153,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-265.529 153,-255.529 149.5,-265.529 156.5,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140217787892288 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140217787892288</title>\n",
       "<polygon fill=\"none\" points=\"90.5,-146.5 90.5,-182.5 215.5,-182.5 215.5,-146.5 90.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-160.8\">dropout_2: Dropout</text>\n",
       "</g>\n",
       "<!-- 140217787892176&#45;&gt;140217787892288 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140217787892176-&gt;140217787892288</title>\n",
       "<path d=\"M153,-219.313C153,-211.289 153,-201.547 153,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-192.529 153,-182.529 149.5,-192.529 156.5,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140217787892624 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140217787892624</title>\n",
       "<polygon fill=\"none\" points=\"0,-73.5 0,-109.5 306,-109.5 306,-73.5 0,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-87.8\">timedistributed_1(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 140217787892288&#45;&gt;140217787892624 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140217787892288-&gt;140217787892624</title>\n",
       "<path d=\"M153,-146.313C153,-138.289 153,-128.547 153,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-119.529 153,-109.529 149.5,-119.529 156.5,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140217787892680 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140217787892680</title>\n",
       "<polygon fill=\"none\" points=\"79,-0.5 79,-36.5 227,-36.5 227,-0.5 79,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-14.8\">activation_1: Activation</text>\n",
       "</g>\n",
       "<!-- 140217787892624&#45;&gt;140217787892680 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140217787892624-&gt;140217787892680</title>\n",
       "<path d=\"M153,-73.3129C153,-65.2895 153,-55.5475 153,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-46.5288 153,-36.5288 149.5,-46.5289 156.5,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ca have a more detailed description of the model. There are more than 3 milion parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 36, 24)        1392        embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 36, 24)        96          embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 36, 512)       1099776     batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 36, 512)       0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 36, 512)       2099200     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 36, 512)       0           lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_1 (TimeDistribut (None, 36, 58)        29754       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 36, 58)        0           timedistributed_1[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 3,230,218\n",
      "Trainable params: 3,230,170\n",
      "Non-trainable params: 48\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fitting the model and generating the poetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a function for the predictions. Starting with a _seed string_, it will predict the next character. Then, the seed together with the next character becomes the new seed and process is repeted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_example():\n",
    "    seed_string=\"i feel i'm knockin' on heaven's door\"\n",
    "    for i in range(500):\n",
    "        x=np.array([char_indices[c] for c in seed_string[-36:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_char = choice(chars, p=preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    print(seed_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything we need to repeatedly fit a few epochs and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "525s - loss: 1.4163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86fde0d588>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, \n",
    "          nb_epoch=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel i'm knockin' on heaven's door,\n",
      "it was senor, for mama come bewin' down there anybody for the middle of the beat of range\n",
      "well, i never did . . . \n",
      "why must you ever seen my wife’s dressed.\n",
      "\n",
      "let me get me in a deck, don't come for you, bully,\n",
      "you got my best friend you do what you have more than in the corn\n",
      "a hangin' hearts.\n",
      "\n",
      "i didn't know if i had to be alone\n",
      "everybody is there to hide\n",
      "and my voice that ruin to the cage,\n",
      "let me change white diamonds you promised?\n",
      "the road is close to the blood./nodds and purple show hard say\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "525s - loss: 1.2455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8760100390>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, \n",
    "          nb_epoch=1, verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel i'm knockin' on heaven's door\n",
      "here comes for the bottle, prayed\n",
      "\n",
      "my love is quarter, your sky's people disappointed through teors\n",
      "and the hanging art work, \"you say i'm as glad\n",
      "you'd better laugh at that useless they seemed\n",
      "sometimes i'm inside to all of my pain\n",
      "you might be happy just move you for it\n",
      "\n",
      "i's looking for my mind./nyou didn't see the groom still wrong\n",
      "here's a million lights along?\n",
      "\n",
      "perfected deck, my do you made me be all i drive you down on your window\n",
      "and you talk to build a series of day\n",
      "the back and yer br\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "530s - loss: 1.2087\n",
      "Epoch 2/2\n",
      "523s - loss: 1.1862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86fdc4dcf8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, \n",
    "          nb_epoch=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel i'm knockin' on heaven's door\n",
      "knock, knockin' on heaven's door\n",
      "knock, knockin' on heaven's door\n",
      "knock, knockin' on heaven's door\n",
      "knock, knock, knock, knock, knockin' on heaven's door\n",
      "knock, knock, knock, knockin' on heaven's door\n",
      "knock, knock, knockin' on heaven's door\n",
      "in a political world\n",
      "\n",
      "i was a-sayin' all the golden light of mirrors\n",
      "but no one left to talk to look so long, i'm going\n",
      "to tell that\n",
      "the hot blowing in the heads\n",
      "flowin' around for silver, lookin' to get it down or never turn about anything you could\n",
      "the pray\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "522s - loss: 1.1680\n",
      "Epoch 2/2\n",
      "521s - loss: 1.1515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86fdc4dcc0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64,\n",
    "          nb_epoch=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel i'm knockin' on heaven's door\n",
      "knock, knock, knockin' on heaven's door\n",
      "try to kill me out of my dreams\n",
      "everybody wants eleven apart\n",
      "\n",
      "i've been cowned and the levee gonna break\n",
      "in cryin' where we were taking away and the heavens are hello\n",
      "\n",
      "wull leaves, baby, everything is gonna break\n",
      "sun has gone blacks into the judge just one with the dirty hot\n",
      "but it was the side of his lady, it's all good\n",
      "it’s all after night, i just saw all the music that we went on what my heart is gone\n",
      "yes, just like pearls shining like you\n",
      "to be time a\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "521s - loss: 1.1368\n",
      "Epoch 2/8\n",
      "521s - loss: 1.1231\n",
      "Epoch 3/8\n",
      "521s - loss: 1.1113\n",
      "Epoch 4/8\n",
      "521s - loss: 1.1006\n",
      "Epoch 5/8\n",
      "521s - loss: 1.0911\n",
      "Epoch 6/8\n",
      "521s - loss: 1.0824\n",
      "Epoch 7/8\n",
      "521s - loss: 1.0752\n",
      "Epoch 8/8\n",
      "521s - loss: 1.0677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86fdc4df60>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, \n",
    "          nb_epoch=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel i'm knockin' on heaven's door\n",
      "knock, knock, knock, knockin' on heaven's door\n",
      "knock, knockin' on heaven's door\n",
      "knock, knock, knockin' on heaven's door\n",
      "knock, knock, knockin' on heaven's door\n",
      "knock, knock, knock, knockin' on heaven's door\n",
      "knock, knock, knock, knockin' on heaven's door\n",
      "knock, knock, knockin' on heaven's door\n",
      "knock, knock, knock, knockin' on heaven's door\n",
      "knock, knock, knockin' on heaven's door\n",
      "knock, knock, knockin' on heaven's door/nnone/nsaying, \"death, you're right now, you know someone must be losing somet\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "522s - loss: 1.0617\n",
      "Epoch 2/4\n",
      "521s - loss: 1.0560\n",
      "Epoch 3/4\n",
      "521s - loss: 1.0507\n",
      "Epoch 4/4\n",
      "522s - loss: 1.0459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86f4097dd8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, \n",
    "          nb_epoch=4, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel i'm knockin' on heaven's door\n",
      "knock, knock, knock, knockin' on heaven's door\n",
      "knock, knock, knock, knockin' on heaven's door\n",
      "knock, knock, knock, knockin' on heaven's door\n",
      "knock, knock, knock knockin' on heaven's door\n",
      "knock, knock, knock, knockin' roll on john\n",
      "\n",
      "you've had my life?\n",
      "you can remember your room, to the higher calling of my lord.\n",
      "\n",
      "the crime has gone black before it may flow\n",
      "when my stage was still in their highway\n",
      "tryin' to break my heart\n",
      "you-\n",
      "hey, you're so hard/nnone/nshe's a tears right all night long\n",
      "she turn\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "521s - loss: 1.0417\n",
      "Epoch 2/4\n",
      "521s - loss: 1.0377\n",
      "Epoch 3/4\n",
      "535s - loss: 1.0338\n",
      "Epoch 4/4\n",
      "542s - loss: 1.0304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86ff74b5c0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, \n",
    "          nb_epoch=4, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel i'm knockin' on heaven's door\n",
      "knock, knock, knock, knockin' on heaven's door\n",
      "knock, knock, knock, knockin' on heaven's door\n",
      "knock, knock, knock, knockin' on heaven's door/nnone/nacross the big hangman comes\n",
      "my warehouse eyes?\n",
      "my are white lady, should i wait?\n",
      "\n",
      "well, it said \"beware we kiss, he is ovin', the levee gonna break\n",
      "now i'm marching to the old man said the mind\n",
      "as the flowers took a clean-cut kid\n",
      "but that's just about did some evil doubt\n",
      "\n",
      "people on the paths and streetched trembles, father of dreams.\n",
      "\n",
      "don't fall ap\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n",
      "542s - loss: 1.0270\n",
      "Epoch 2/42\n",
      "558s - loss: 1.0238\n",
      "Epoch 3/42\n",
      "553s - loss: 1.0210\n",
      "Epoch 4/42\n",
      "532s - loss: 1.0181\n",
      "Epoch 5/42\n",
      "533s - loss: 1.0157\n",
      "Epoch 6/42\n",
      "523s - loss: 1.0135\n",
      "Epoch 7/42\n",
      "527s - loss: 1.0114\n",
      "Epoch 8/42\n",
      "533s - loss: 1.0090\n",
      "Epoch 9/42\n",
      "530s - loss: 1.0067\n",
      "Epoch 10/42\n",
      "540s - loss: 1.0048\n",
      "Epoch 11/42\n",
      "537s - loss: 1.0031\n",
      "Epoch 12/42\n",
      "530s - loss: 1.0011\n",
      "Epoch 13/42\n",
      "524s - loss: 0.9992\n",
      "Epoch 14/42\n",
      "537s - loss: 0.9978\n",
      "Epoch 15/42\n",
      "531s - loss: 0.9962\n",
      "Epoch 16/42\n",
      "524s - loss: 0.9947\n",
      "Epoch 17/42\n",
      "534s - loss: 0.9929\n",
      "Epoch 18/42\n",
      "545s - loss: 0.9918\n",
      "Epoch 19/42\n",
      "546s - loss: 0.9903\n",
      "Epoch 20/42\n",
      "550s - loss: 0.9891\n",
      "Epoch 21/42\n",
      "542s - loss: 0.9876\n",
      "Epoch 22/42\n",
      "526s - loss: 0.9861\n",
      "Epoch 23/42\n",
      "523s - loss: 0.9850\n",
      "Epoch 24/42\n",
      "524s - loss: 0.9839\n",
      "Epoch 25/42\n",
      "525s - loss: 0.9828\n",
      "Epoch 26/42\n",
      "525s - loss: 0.9818\n",
      "Epoch 27/42\n",
      "523s - loss: 0.9810\n",
      "Epoch 28/42\n",
      "523s - loss: 0.9797\n",
      "Epoch 29/42\n",
      "523s - loss: 0.9790\n",
      "Epoch 30/42\n",
      "523s - loss: 0.9776\n",
      "Epoch 31/42\n",
      "523s - loss: 0.9768\n",
      "Epoch 32/42\n",
      "523s - loss: 0.9758\n",
      "Epoch 33/42\n",
      "523s - loss: 0.9750\n",
      "Epoch 34/42\n",
      "523s - loss: 0.9740\n",
      "Epoch 35/42\n",
      "523s - loss: 0.9734\n",
      "Epoch 36/42\n",
      "523s - loss: 0.9722\n",
      "Epoch 37/42\n",
      "524s - loss: 0.9716\n",
      "Epoch 38/42\n",
      "524s - loss: 0.9707\n",
      "Epoch 39/42\n",
      "524s - loss: 0.9701\n",
      "Epoch 40/42\n",
      "523s - loss: 0.9690\n",
      "Epoch 41/42\n",
      "523s - loss: 0.9685\n",
      "Epoch 42/42\n",
      "523s - loss: 0.9679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86f40ba358>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, \n",
    "          nb_epoch=42, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel i'm knockin' on heaven's door/nnone/nbehind every minute before.\n",
      "i and i\n",
      "in creation where one's nature neither honors nor forgives.\n",
      "i and i\n",
      "one said to the fine while my love is right, but i know they called and i can't let go, won't let go, and i can't let go, won't let go, and i can't let go, won't let go\n",
      "and i can't get me baby, i'm making love of my love.\n",
      "i'd be honest with me if only you knew\n",
      "\n",
      "hey, everybody's got killed them anymore\n",
      "take a look at me baby\n",
      "(just take a look at me baby\n",
      "(just take a look at me baby\n",
      "i'm \n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel i'm knockin' on heaven's door\n",
      "knock, knock, knockin' on heaven's door\n",
      "knock, knock, knockin' on heaven's door\n",
      "knock, knock, knockin' on heaven's door\n",
      "knock, knockin' on heaven's door\n",
      "\n",
      "knock, knock, knockin' on heaven's door\n",
      "knock, knock, knockin' on heaven's door\n",
      "knock, knock, knockin' on heaven's door/nnone/nif not for you\n",
      "my sky would won't be with me\n",
      "\n",
      "beyond the horizon, 'neath the strength of strings\n",
      "no voice can hope to hum.\n",
      "\n",
      "dead man, dead man\n",
      "when will you arise?\n",
      "cobwebs in your mind\n",
      "dust upon your eyes./nnone/nnone/\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel i'm knockin' on heaven's door\n",
      "knock, knock, knockin' on heaven's door\n",
      "knock, knock, knockin' on heaven's door\n",
      "knock, knock, knockin' on heaven's door/nsayin', \"christ way you down or drive you more\n",
      "and your mother was a recognize here\n",
      "the streets are getting captains\n",
      "\n",
      "all i really want to do\n",
      "when my price comes wrong\n",
      "\n",
      "well, gettin' there was where i am, at the wind\n",
      "news of the mississippi moon\n",
      "i was or laughing struck with my child.\n",
      "\n",
      "three boy had been lost in this air.\n",
      "they're your friend says, \" they took a trip\"\"get out \n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's print 2000 characters of poetry into an output file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_string=\"i feel i'm knockin' on heaven's door\"\n",
    "for i in range(2000):\n",
    "    x=np.array([char_indices[c] for c in seed_string[-36:]])[np.newaxis,:]\n",
    "    preds = model.predict(x, verbose=0)[0][-1]\n",
    "    preds = preds/np.sum(preds)\n",
    "    next_char = choice(chars, p=preds)\n",
    "    seed_string = seed_string + next_char\n",
    "f = open('generatedtext.txt','w')\n",
    "f.write(seed_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Nobelizer\n",
    "\n",
    "## by Catalin Vasii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I thoght a little tool to get a Nobel Prize in lit would be useful. This notebook is a recurrent neural network in the style of [Jeremy Howard's fast.ai](http://www.fast.ai/) that has been trained onall Bob Dylan song lyrics to predict the next character for each given sequence of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout\n",
    "from keras.layers import TimeDistributed, Activation, LSTM\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from numpy.random import choice\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 563887\n"
     ]
    }
   ],
   "source": [
    "path = 'dylansongs.txt'\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flowers on the hillside blooming crazy\r\n",
      "Crickets talking back and forth in rhyme\r\n",
      "Blue river running slow and lazy\r\n",
      "I could stay with you forever and never realize the time\r\n",
      "\r\n",
      "Situations have ended sad\r\n",
      "Relationships have all been bad\r\n",
      "Mine have been like Verlaine's and Rimbaud's\r\n",
      "But there's no way I can compare\r\n",
      "All them scenes to this affair,\r\n",
      "You're gonna make me lonesome when you go\r\n",
      "\r\n",
      "You're gonna make me wonder what I'm doing\r\n",
      "Staying far behind without you\r\n",
      "You're gonna make me wonder what I'm saying\r\n",
      "You're gonna make me give myself a good talking to\r\n",
      "\r\n",
      "I'll look for you in old Honolulu\r\n",
      "San Francisco or Ashtabula\r\n",
      "You're gonna have to leave me now I know\r\n",
      "But I'll see you in the sky above\r\n",
      "In the tall grass in the ones I love\r\n",
      "You're gonna make me lonesome when you go/nNone/nNone/n"
     ]
    }
   ],
   "source": [
    "!tail {path} -n23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 58\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-./0123456789:;?[]abcdefghijklmnopqrstuvwxy'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are constructing two dictionaries, mapping characters to numbers (index in the text) and conversely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46, 31, 40, 2, 46, 34, 41, 47, 45, 27]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ten thousand men on a hill,\\nsome of 'm goin' down, some of 'm gonna ge\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 563852\n"
     ]
    }
   ],
   "source": [
    "maxlen = 36\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(idx) - maxlen+1):\n",
    "    sentences.append(idx[i: i + maxlen])\n",
    "    next_chars.append(idx[i+1: i+maxlen+1])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46, 31, 40, 2, 46, 34, 41, 47, 45, 27, 40, 30, 2, 39, 31, 40, 2, 41, 40, 2, 27, 2, 34, 35, 38, 38, 8, 1, 45, 41, 39, 31, 2, 41, 32, 2], [31, 40, 2, 46, 34, 41, 47, 45, 27, 40, 30, 2, 39, 31, 40, 2, 41, 40, 2, 27, 2, 34, 35, 38, 38, 8, 1, 45, 41, 39, 31, 2, 41, 32, 2, 5]]\n",
      "[[31, 40, 2, 46, 34, 41, 47, 45, 27, 40, 30, 2, 39, 31, 40, 2, 41, 40, 2, 27, 2, 34, 35, 38, 38, 8, 1, 45, 41, 39, 31, 2, 41, 32, 2, 5], [40, 2, 46, 34, 41, 47, 45, 27, 40, 30, 2, 39, 31, 40, 2, 41, 40, 2, 27, 2, 34, 35, 38, 38, 8, 1, 45, 41, 39, 31, 2, 41, 32, 2, 5, 39]]\n"
     ]
    }
   ],
   "source": [
    "print('first two sentences are: ' ,sentences[:2])\n",
    "print('first two next chars are: ' ,next_chars[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((563850, 36), (563850, 36))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.shape, next_chars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is Jeremy Howard's approach to use embeddings instead of one hot encodings. We set the number of latent factor to 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short Time Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras has three types of recurrent layers: LSTM, GRU and SimpleRNN. The first two are more complex, I will only put a scheme of a LSTM, i.e. Long Short Time Memory: \n",
    "\n",
    "![](Long_Short_Term_Memory.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=maxlen),\n",
    "        BatchNormalization(),    \n",
    "        LSTM(512, input_dim=n_fac,return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        LSTM(512, return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size)),\n",
    "        Activation('softmax')\n",
    "    ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphically, the network looks like below, but keep in mind that each of the two recurrent layers look like in the above picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"629pt\" viewBox=\"0.00 0.00 314.00 629.00\" width=\"314pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-625 310,-625 310,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140682522267488 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140682522267488</title>\n",
       "<polygon fill=\"none\" points=\"56.5,-584.5 56.5,-620.5 249.5,-620.5 249.5,-584.5 56.5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-598.8\">embedding_input_2: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140682522266536 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140682522266536</title>\n",
       "<polygon fill=\"none\" points=\"72.5,-511.5 72.5,-547.5 233.5,-547.5 233.5,-511.5 72.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-525.8\">embedding_2: Embedding</text>\n",
       "</g>\n",
       "<!-- 140682522267488&#45;&gt;140682522266536 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140682522267488-&gt;140682522266536</title>\n",
       "<path d=\"M153,-584.313C153,-576.289 153,-566.547 153,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-557.529 153,-547.529 149.5,-557.529 156.5,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140682522266648 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140682522266648</title>\n",
       "<polygon fill=\"none\" points=\"26.5,-438.5 26.5,-474.5 279.5,-474.5 279.5,-438.5 26.5,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-452.8\">batchnormalization_2: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140682522266536&#45;&gt;140682522266648 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140682522266536-&gt;140682522266648</title>\n",
       "<path d=\"M153,-511.313C153,-503.289 153,-493.547 153,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-484.529 153,-474.529 149.5,-484.529 156.5,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140682522266704 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140682522266704</title>\n",
       "<polygon fill=\"none\" points=\"104,-365.5 104,-401.5 202,-401.5 202,-365.5 104,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-379.8\">lstm_3: LSTM</text>\n",
       "</g>\n",
       "<!-- 140682522266648&#45;&gt;140682522266704 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140682522266648-&gt;140682522266704</title>\n",
       "<path d=\"M153,-438.313C153,-430.289 153,-420.547 153,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-411.529 153,-401.529 149.5,-411.529 156.5,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140682522266760 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140682522266760</title>\n",
       "<polygon fill=\"none\" points=\"90.5,-292.5 90.5,-328.5 215.5,-328.5 215.5,-292.5 90.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-306.8\">dropout_3: Dropout</text>\n",
       "</g>\n",
       "<!-- 140682522266704&#45;&gt;140682522266760 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140682522266704-&gt;140682522266760</title>\n",
       "<path d=\"M153,-365.313C153,-357.289 153,-347.547 153,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-338.529 153,-328.529 149.5,-338.529 156.5,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140682522266984 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140682522266984</title>\n",
       "<polygon fill=\"none\" points=\"104,-219.5 104,-255.5 202,-255.5 202,-219.5 104,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-233.8\">lstm_4: LSTM</text>\n",
       "</g>\n",
       "<!-- 140682522266760&#45;&gt;140682522266984 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140682522266760-&gt;140682522266984</title>\n",
       "<path d=\"M153,-292.313C153,-284.289 153,-274.547 153,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-265.529 153,-255.529 149.5,-265.529 156.5,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140682522266928 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140682522266928</title>\n",
       "<polygon fill=\"none\" points=\"90.5,-146.5 90.5,-182.5 215.5,-182.5 215.5,-146.5 90.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-160.8\">dropout_4: Dropout</text>\n",
       "</g>\n",
       "<!-- 140682522266984&#45;&gt;140682522266928 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140682522266984-&gt;140682522266928</title>\n",
       "<path d=\"M153,-219.313C153,-211.289 153,-201.547 153,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-192.529 153,-182.529 149.5,-192.529 156.5,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140682522267208 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140682522267208</title>\n",
       "<polygon fill=\"none\" points=\"0,-73.5 0,-109.5 306,-109.5 306,-73.5 0,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-87.8\">timedistributed_2(dense_2): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 140682522266928&#45;&gt;140682522267208 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140682522266928-&gt;140682522267208</title>\n",
       "<path d=\"M153,-146.313C153,-138.289 153,-128.547 153,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-119.529 153,-109.529 149.5,-119.529 156.5,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140682522267320 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140682522267320</title>\n",
       "<polygon fill=\"none\" points=\"79,-0.5 79,-36.5 227,-36.5 227,-0.5 79,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-14.8\">activation_2: Activation</text>\n",
       "</g>\n",
       "<!-- 140682522267208&#45;&gt;140682522267320 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140682522267208-&gt;140682522267320</title>\n",
       "<path d=\"M153,-73.3129C153,-65.2895 153,-55.5475 153,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-46.5288 153,-36.5288 149.5,-46.5289 156.5,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ca have a more detailed description of the model. There are more than 3 milion parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 36, 24)        1392        embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 36, 24)        96          embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 36, 512)       1099776     batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 36, 512)       0           lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, 36, 512)       2099200     dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 36, 512)       0           lstm_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_2 (TimeDistribut (None, 36, 58)        29754       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 36, 58)        0           timedistributed_2[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 3,230,218\n",
      "Trainable params: 3,230,170\n",
      "Non-trainable params: 48\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fitting the model and generating the poetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a function for the predictions. Starting with a _seed string_, it will predict the next character. Then, the seed together with the next character becomes the new seed and process is repeted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_example():\n",
    "    seed_string=\"i feel i'm knockin' on heaven's door\"\n",
    "    for i in range(500):\n",
    "        x=np.array([char_indices[c] for c in seed_string[-36:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_char = choice(chars, p=preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    print(seed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "544s - loss: 1.4147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff333809898>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, \n",
    "          nb_epoch=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel i'm knockin' on heaven's door\n",
      "and we dreamt everything you don't know what he's in\n",
      "\n",
      "everybody's got no braind from shack\n",
      "it's so long with you.\n",
      "\n",
      "who's gonna let it down to bove,\n",
      "your picture that you ain't got up they flamed out\n",
      "\n",
      "maybe i was plain: i feel that will remember what's mine to hell\n",
      "\n",
      "oh, baby, please! he will haunt me by\n",
      "\n",
      "well, i got the floorson of the locusts\n",
      "shame up around your teeth, glowing for the summertime,\n",
      "i'm on the street when it was closer, the middle of the ground\n",
      "the walls shall be staylight in the\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "539s - loss: 1.2449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3338187b8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, \n",
    "          nb_epoch=1, verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel i'm knockin' on heaven's door\n",
      "he stood seen them cold\n",
      "i was up to me you have heard the glass\n",
      "\n",
      "my conscience did up yet\n",
      "and i cry alone at the police hold of the sweet\n",
      "and his tune did hear?\n",
      "yes, but i'm in the lay, like sugar as a couple\n",
      "and i'm going\n",
      "i'm so glad\n",
      "ain't made of the mornin' like you'd have my heart/nnone/npreacher in a hill for the red roof, stay\n",
      "we shall rush a soriet perceive headed\n",
      "and she began to have heard it too much hounds in her house away\n",
      "you have got a highway of the children trying to get to be s\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "542s - loss: 1.2083\n",
      "Epoch 2/2\n",
      "544s - loss: 1.1857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff33380b668>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, \n",
    "          nb_epoch=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel i'm knockin' on heaven's door\n",
      "knock, knockin' on heaven's door\n",
      "knock, knockin' on heaven's shootin' stranger\n",
      "the cat's in the well, we were born in time.\n",
      "\n",
      "i was talkin' to the bundon and where must be\n",
      "in a storm\"/nnone/nout, the last way, i can’t even remember what she did and knocked out and he just wanted to do what they'll be flyin'\n",
      "but i figured her eyes are expecting the street.\n",
      "\n",
      "he's the rain hates have heard of rules. he tried to do to stay behind\n",
      "\n",
      "the meadows well-many auserums\n",
      "don't let her defend to die\n",
      "\n",
      "i know to\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64,\n",
    "          nb_epoch=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, \n",
    "          nb_epoch=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, \n",
    "          nb_epoch=4, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, \n",
    "          nb_epoch=4, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, \n",
    "          nb_epoch=42, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_string=\"i feel i'm knockin' on heaven's door\"\n",
    "for i in range(2000):\n",
    "    x=np.array([char_indices[c] for c in seed_string[-36:]])[np.newaxis,:]\n",
    "    preds = model.predict(x, verbose=0)[0][-1]\n",
    "    preds = preds/np.sum(preds)\n",
    "    next_char = choice(chars, p=preds)\n",
    "    seed_string = seed_string + next_char\n",
    "f = open('generatedtext.txt','w')\n",
    "f.write(seed_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
